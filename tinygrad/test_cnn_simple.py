#!/usr/bin/env python3
"""
ç®€åŒ–çš„CNNæµ‹è¯• - ä½¿ç”¨åŸºç¡€è¿ç®—å®ç°
"""

import numpy as np
from tensor import Tensor
from module import Conv2d, MaxPool2d, Flatten, Linear, ReLU, Sequential
from loss import cross_entropy

def test_basic_operations():
    """æµ‹è¯•åŸºç¡€è¿ç®—"""
    print("=== æµ‹è¯•åŸºç¡€è¿ç®— ===")
    
    # æµ‹è¯•padæ“ä½œ
    x = Tensor(np.random.randn(2, 3, 4, 4))
    print(f"åŸå§‹å½¢çŠ¶: {x.shape}")
    
    padded = x.pad(((0, 0), (0, 0), (1, 1), (1, 1)))
    print(f"å¡«å……åå½¢çŠ¶: {padded.shape}")
    
    # æµ‹è¯•ç´¢å¼•æ“ä½œ
    slice_x = x[0:1, :, 1:3, 1:3]
    print(f"åˆ‡ç‰‡åå½¢çŠ¶: {slice_x.shape}")
    
    # æµ‹è¯•maxæ“ä½œ
    max_val = x.max()
    print(f"æœ€å¤§å€¼: {max_val.data}")
    
    # æµ‹è¯•transpose
    transposed = x.transpose((0, 1, 3, 2))
    print(f"è½¬ç½®åå½¢çŠ¶: {transposed.shape}")
    
    print("åŸºç¡€è¿ç®—æµ‹è¯•é€šè¿‡ï¼\n")

def test_simple_conv():
    """æµ‹è¯•ç®€åŒ–çš„å·ç§¯å®ç°"""
    print("=== æµ‹è¯•ç®€åŒ–å·ç§¯ ===")
    
    # åˆ›å»ºå°çš„æµ‹è¯•æ•°æ®
    x = Tensor(np.random.randn(1, 2, 4, 4))
    print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
    
    # åˆ›å»ºç®€å•çš„å·ç§¯å±‚
    conv = Conv2d(2, 3, kernel_size=3, padding=1)
    print(f"å·ç§¯å±‚: {conv}")
    
    try:
        # å‰å‘ä¼ æ’­
        output = conv(x)
        print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")
        
        # ç®€å•çš„åå‘ä¼ æ’­æµ‹è¯•
        loss = output.sum()
        loss.backward()
        
        print("ç®€åŒ–å·ç§¯æµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"å·ç§¯æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    print()

def test_simple_maxpool():
    """æµ‹è¯•ç®€åŒ–çš„æœ€å¤§æ± åŒ–"""
    print("=== æµ‹è¯•ç®€åŒ–æœ€å¤§æ± åŒ– ===")
    
    x = Tensor(np.random.randn(1, 2, 4, 4))
    print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
    
    maxpool = MaxPool2d(kernel_size=2, stride=2)
    
    try:
        output = maxpool(x)
        print(f"æ± åŒ–è¾“å‡ºå½¢çŠ¶: {output.shape}")
        
        loss = output.sum()
        loss.backward()
        
        print("ç®€åŒ–æœ€å¤§æ± åŒ–æµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"æœ€å¤§æ± åŒ–æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    print()

def test_simple_network():
    """æµ‹è¯•ç®€å•çš„ç½‘ç»œ"""
    print("=== æµ‹è¯•ç®€å•ç½‘ç»œ ===")
    
    # åˆ›å»ºéå¸¸ç®€å•çš„ç½‘ç»œ
    model = Sequential(
        Conv2d(1, 4, kernel_size=3, padding=1),  # ä¿æŒå°ºå¯¸
        ReLU(),
        MaxPool2d(kernel_size=2),  # å‡åŠå°ºå¯¸
        Flatten(),
        Linear(4 * 2 * 2, 2)  # 4x4 -> 2x2 after pooling
    )
    
    print(f"æ¨¡å‹: {model}")
    
    # å°çš„è¾“å…¥
    x = Tensor(np.random.randn(1, 1, 4, 4))
    print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
    
    try:
        output = model(x)
        print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")
        
        # è®¡ç®—æŸå¤±
        target = Tensor([0])
        probs = output.softmax()
        loss = cross_entropy(probs, target)
        print(f"æŸå¤±: {loss.data}")
        
        # åå‘ä¼ æ’­
        loss.backward()
        print("ç®€å•ç½‘ç»œæµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"ç½‘ç»œæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    print()

if __name__ == "__main__":
    print("å¼€å§‹ç®€åŒ–CNNæµ‹è¯•...\n")
    
    try:
        test_basic_operations()
        test_simple_conv()
        test_simple_maxpool()
        test_simple_network()
        
        print("ğŸ‰ æ‰€æœ‰ç®€åŒ–æµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        import traceback
        print(f"âŒ æµ‹è¯•å¤±è´¥: {type(e).__name__} - {e}")
        traceback.print_exc() 